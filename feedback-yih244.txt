I like the way your presentation is structured. you talk about which biases you are covering and have a good layout. i would like more information on how to handle or account for this bias. for example, while talking about observer bias, you show there is a non linear relationship. how would one fix or account for such a bias in your classifiers? showing how to handle bias while training and predicting from your classifiers could help make your project more holistic. but overall, great project and i learnt a lot as someone who doesn't know a lot about machine learning, it was informative and made sense to me